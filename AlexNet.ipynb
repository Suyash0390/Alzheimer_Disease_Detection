{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb0f46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras-Preprocessing in d:\\anaconda\\install\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in d:\\anaconda\\install\\lib\\site-packages (from Keras-Preprocessing) (1.21.5)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\anaconda\\install\\lib\\site-packages (from Keras-Preprocessing) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in d:\\anaconda\\install\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.21)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.30.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.42.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in d:\\anaconda\\install\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda\\install\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda\\install\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda\\install\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\anaconda\\install\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda\\install\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda\\install\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\install\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\install\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\install\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\install\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda\\install\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda\\install\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n",
      "TF version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras-Preprocessing\n",
    "!pip install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Add\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras import Model\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"TF version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfb3c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 files belonging to 4 classes.\n",
      "Using 4097 files for training.\n",
      "Found 5121 files belonging to 4 classes.\n",
      "Using 1024 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\"C:/Users/hp/Documents/suyash/suyash/Alzheimer_Dataset/train\",    \n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    image_size=(227, 227),\n",
    "    shuffle=True,\n",
    "    seed=42,                                                   \n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",                                                  \n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    " )\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\"C:/Users/hp/Documents/suyash/suyash/Alzheimer_Dataset/train\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",                                                   \n",
    "  seed=42,\n",
    "  image_size=(227, 227),\n",
    "  batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aeb0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\Install\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "0.0 0.9853845\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f285d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd9c647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 55, 55, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 27, 256)       2973952   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 27, 27, 256)       3211520   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 27, 27, 384)       2457984   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 27, 27, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 27, 27, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 27, 27, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 27, 27, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 27, 27, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 27, 27, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 43264)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              177213440 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 16388     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 206,237,572\n",
      "Trainable params: 206,233,540\n",
      "Non-trainable params: 4,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_class_units = 4\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(96, (11,11),strides=(4,4), activation='relu', input_shape=(227, 227, 3)),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.MaxPooling2D(2, strides=(2,2)),\n",
    "  tf.keras.layers.Conv2D(256, (11,11),strides=(1,1), activation='relu',padding=\"same\"),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Conv2D(256, (7,7),strides=(1,1), activation='relu',padding=\"same\"),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Conv2D(384, (5,5),strides=(1,1), activation='relu',padding=\"same\"),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu',padding=\"same\"),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.MaxPooling2D(2, strides=(2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(4096, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.8),\n",
    "  tf.keras.layers.Dense(4096, activation='relu'),\n",
    "  tf.keras.layers.Dense(output_class_units, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600b1863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1047s 16s/step - loss: 24.2640 - accuracy: 0.4503 - val_loss: 19811.3516 - val_accuracy: 0.5195\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 1003s 15s/step - loss: 1.2725 - accuracy: 0.4313 - val_loss: 621.0696 - val_accuracy: 0.5195\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 996s 15s/step - loss: 1.0859 - accuracy: 0.4213 - val_loss: 26.2311 - val_accuracy: 0.5215\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 996s 15s/step - loss: 1.0464 - accuracy: 0.4950 - val_loss: 1.8114 - val_accuracy: 0.5195\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 996s 15s/step - loss: 1.0463 - accuracy: 0.4950 - val_loss: 1.4340 - val_accuracy: 0.5195\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 994s 15s/step - loss: 1.0370 - accuracy: 0.4945 - val_loss: 0.9815 - val_accuracy: 0.5195\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 995s 15s/step - loss: 1.0444 - accuracy: 0.4950 - val_loss: 1.0036 - val_accuracy: 0.5195\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 997s 15s/step - loss: 1.0449 - accuracy: 0.4950 - val_loss: 0.9951 - val_accuracy: 0.5195\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 1216s 19s/step - loss: 1.0538 - accuracy: 0.4957 - val_loss: 1.0082 - val_accuracy: 0.5195\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 1016s 16s/step - loss: 1.0433 - accuracy: 0.4950 - val_loss: 1.0084 - val_accuracy: 0.5195\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(lr=lr), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "epochs=10\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720c988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info( test_gen, preds, print_code, save_dir, subject ):\n",
    "    class_dict=test_gen.class_indices\n",
    "    labels= test_gen.labels\n",
    "    file_names= test_gen.filenames \n",
    "    error_list=[]\n",
    "    true_class=[]\n",
    "    pred_class=[]\n",
    "    prob_list=[]\n",
    "    new_dict={}\n",
    "    error_indices=[]\n",
    "    y_pred=[]\n",
    "    for key,value in class_dict.items():\n",
    "        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n",
    "    # store new_dict as a text fine in the save_dir\n",
    "    classes=list(new_dict.values())     # list of string of class names     \n",
    "    errors=0      \n",
    "    for i, p in enumerate(preds):\n",
    "        pred_index=np.argmax(p)         \n",
    "        true_index=labels[i]  # labels are integer values\n",
    "        if pred_index != true_index: # a misclassification has occurred\n",
    "            error_list.append(file_names[i])\n",
    "            true_class.append(new_dict[true_index])\n",
    "            pred_class.append(new_dict[pred_index])\n",
    "            prob_list.append(p[pred_index])\n",
    "            error_indices.append(true_index)            \n",
    "            errors=errors + 1\n",
    "        y_pred.append(pred_index)    \n",
    "    if print_code !=0:\n",
    "        if errors>0:\n",
    "            if print_code>errors:\n",
    "                r=errors\n",
    "            else:\n",
    "                r=print_code           \n",
    "            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n",
    "            print_in_color(msg, (0,255,0),(55,65,80))\n",
    "            for i in range(r):                \n",
    "                split1=os.path.split(error_list[i])                \n",
    "                split2=os.path.split(split1[0])                \n",
    "                fname=split2[1] + '/' + split1[1]\n",
    "                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n",
    "                print_in_color(msg, (255,255,255), (55,65,60))\n",
    "                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n",
    "        else:\n",
    "            msg='With accuracy of 100 % there are no errors to print'\n",
    "            print_in_color(msg, (0,255,0),(55,65,80))\n",
    "    if errors>0:\n",
    "        plot_bar=[]\n",
    "        plot_class=[]\n",
    "        for  key, value in new_dict.items():        \n",
    "            count=error_indices.count(key) \n",
    "            if count!=0:\n",
    "                plot_bar.append(count) # list containg how many times a class c had an error\n",
    "                plot_class.append(value)   # stores the class \n",
    "        fig=plt.figure()\n",
    "        fig.set_figheight(len(plot_class)/3)\n",
    "        fig.set_figwidth(10)\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        for i in range(0, len(plot_class)):\n",
    "            c=plot_class[i]\n",
    "            x=plot_bar[i]\n",
    "            plt.barh(c, x, )\n",
    "            plt.title( ' Errors by Class on Test Set')\n",
    "    y_true= np.array(labels)        \n",
    "    y_pred=np.array(y_pred)\n",
    "    if len(classes)<= 40:\n",
    "        # create a confusion matrix \n",
    "        cm = confusion_matrix(y_true, y_pred )        \n",
    "        length=len(classes)\n",
    "        if length<8:\n",
    "            fig_width=8\n",
    "            fig_height=8\n",
    "        else:\n",
    "            fig_width= int(length * .5)\n",
    "            fig_height= int(length * .5)\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
    "        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n",
    "        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "    clr = classification_report(y_true, y_pred, target_names=classes)\n",
    "    print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c9c412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_in_color(txt_msg,fore_tupple,back_tupple,):\n",
    "    rf,gf,bf=fore_tupple\n",
    "    rb,gb,bb=back_tupple\n",
    "    msg='{0}' + txt_msg\n",
    "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n",
    "    print(msg .format(mat), flush=True)\n",
    "    print('\\33[0m', flush=True) # returns default print color to back to black\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f12fa08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 66s 4s/step - loss: 1.0084 - accuracy: 0.5195\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(val_ds)\n",
    "\n",
    "model.save(\"alex.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc865198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "shutil.rmtree('C:/Users/hp/Documents/suyash/suyash/Alzheimer_Dataset/train')\n",
    "\n",
    "history.params\n",
    "history.history.keys()\n",
    "type(history.history['loss'])\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
