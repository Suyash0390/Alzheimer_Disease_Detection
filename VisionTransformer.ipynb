{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c329fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras-Preprocessing in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from Keras-Preprocessing) (1.21.5)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from Keras-Preprocessing) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\tanay salve\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras-Preprocessing\n",
    "!pip install tensorflow\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Import all the libraries \n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image, ImageOps  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'plotly_white'\n",
    "from plotly.subplots import make_subplots\n",
    "init_notebook_mode(connected=True)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Concatenate, Flatten, MaxPooling2D, Conv2D\n",
    "from  tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Add\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras import Model\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"TF version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3930b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 files belonging to 4 classes.\n",
      "Using 4097 files for training.\n",
      "Found 5121 files belonging to 4 classes.\n",
      "Using 1024 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\"C:/Users/TANAY SALVE/Downloads/suyash/Alzheimer_Dataset/train\",    \n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    image_size=(227, 227),\n",
    "    shuffle=True,\n",
    "    seed=42,                                                   \n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",                                                  \n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    " )\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\"C:/Users/TANAY SALVE/Downloads/suyash/Alzheimer_Dataset/train\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",                                                   \n",
    "  seed=42,\n",
    "  image_size=(227, 227),\n",
    "  batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552c3877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.9853845\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d26b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6900dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class AttrDict(dict):\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __getattr__ = dict.__getitem__\n",
    "\n",
    "\n",
    "def plot_grid_ds(ds, model=None, size=(3, 3), figsize=(10, 10)):\n",
    "    from copy import copy\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "    \n",
    "    ds_ = copy(ds)\n",
    "    n = size[0] * size[1]\n",
    "    \n",
    "    if isinstance(ds_, tf.keras.preprocessing.image.DirectoryIterator):\n",
    "        class_names = list(ds.class_indices.keys())\n",
    "        iterator = list(next(ds_))\n",
    "        iterator = tuple([i[:n] for i in iterator])\n",
    "        X_batch, y_batch = iterator\n",
    "        y_batch = y_batch.astype(int)\n",
    "    else:\n",
    "        class_names = ds_.class_names\n",
    "        iterator = ds_.unbatch().shuffle(n).batch(n).take(1)\n",
    "        X_batch, y_batch = next(iterator)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    grid = ImageGrid(\n",
    "        fig,\n",
    "        111,\n",
    "        nrows_ncols=size,\n",
    "        axes_pad=0.3,\n",
    "    )\n",
    "    y_hat_batch = model.predict(X_batch).argmax(axis=-1) if model else y_batch\n",
    "    for X, y, y_hat, ax in zip(X_batch, y_batch, y_hat_batch, grid):\n",
    "        title = (\n",
    "            f\"{class_names[y]} (true) - {class_names[y_hat]} (pred)\"\n",
    "            if model\n",
    "            else f\"{class_names[y]}\"\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)\n",
    "        ax.imshow(X, cmap=\"gray\")\n",
    "    return grid\n",
    "\n",
    "\n",
    "class BalancedSparseCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "    def __init__(self, name=\"balanced_sparse_categorical_accuracy\", dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_flat = y_true\n",
    "        if y_true.shape.ndims == y_pred.shape.ndims:\n",
    "            y_flat = tf.squeeze(y_flat, axis=[-1])\n",
    "        y_true_int = tf.cast(y_flat, tf.int32)\n",
    "\n",
    "        cls_counts = tf.math.bincount(y_true_int)\n",
    "        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n",
    "        weight = tf.gather(cls_counts, y_true_int)\n",
    "        return super().update_state(y_true, y_pred, sample_weight=weight)\n",
    "\n",
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "\n",
    "class PatchEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = tf.keras.layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "\n",
    "class ViTClassfier(tf.keras.models.Model):\n",
    "    CONFIG = {\n",
    "        \"patch_size\": 6,\n",
    "        \"embedding_dim\": 32,\n",
    "        \"n_heads\": 2,\n",
    "        \"n_transformers\": 1,\n",
    "        \"transformer_units\": [64, 32],\n",
    "        \"transformer_dropout\": 0.1,\n",
    "        \"mlp_units\": [2048, 1024],\n",
    "        \"mlp_dropout\": 0.1,\n",
    "    }\n",
    "\n",
    "    def __init__(self, input_shape, n_classes, config={}):\n",
    "        super(ViTClassfier, self).__init__()\n",
    "\n",
    "        self._config = AttrDict(\n",
    "            **{\n",
    "                **self.CONFIG,\n",
    "                **config,\n",
    "                \"input_shape\": input_shape,\n",
    "                \"n_classes\": n_classes,\n",
    "            }\n",
    "        )\n",
    "        self._construct_model()\n",
    "\n",
    "    def call(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def _construct_model(self):\n",
    "        config = self._config\n",
    "\n",
    "        num_patches = (config.input_shape[0] // config.patch_size) ** 2\n",
    "\n",
    "        inputs = tf.keras.layers.Input(shape=config.input_shape)\n",
    "\n",
    "        patches = Patches(config.patch_size)(inputs)\n",
    "        # Encode patches.\n",
    "        encoded_patches = PatchEncoder(num_patches, config.embedding_dim)(patches)\n",
    "\n",
    "        # Create multipletf.keras.layers of the Transformer block.\n",
    "        for _ in range(config.n_transformers):\n",
    "            # Layer normalization 1.\n",
    "            x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "            # Create a multi-head attention layer.\n",
    "            attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "                num_heads=config.n_heads, key_dim=config.embedding_dim, dropout=0.1\n",
    "            )(x1, x1)\n",
    "            # Skip connection 1.\n",
    "            x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
    "            # Layer normalization 2.\n",
    "            x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "            # MLP.\n",
    "            for units in config.transformer_units:\n",
    "                x3 = tf.keras.layers.Dense(units, activation=tf.nn.gelu)(x3)\n",
    "                x3 = tf.keras.layers.Dropout(config.transformer_dropout)(x3)\n",
    "\n",
    "            # Skip connection 2.\n",
    "            encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "        # Create a [batch_size, projection_dim] tensor.\n",
    "        features = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        features = tf.keras.layers.Flatten()(features)\n",
    "        features = tf.keras.layers.Dropout(0.5)(features)\n",
    "        # Add MLP.\n",
    "        for units in config.mlp_units:\n",
    "            features = tf.keras.layers.Dense(units, activation=tf.nn.gelu)(features)\n",
    "            features = tf.keras.layers.Dropout(config.mlp_dropout)(features)\n",
    "        # Classify outputs.\n",
    "        logits = tf.keras.layers.Dense(config.n_classes)(features)\n",
    "        # Create the Keras model.\n",
    "        self._model = tf.keras.models.Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd44ad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "hparams = AttrDict(\n",
    "    image_size=(64, 64, 3),\n",
    "    n_classes=4,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "ds = tf.keras.preprocessing.image_dataset_from_directory(\"C:/Users/TANAY SALVE/Downloads/suyash/Alzheimer_Dataset/train\", image_size=hparams.image_size[:-1], batch_size=hparams.batch_size)\n",
    "train_split = round(0.8 * ds.cardinality().numpy()) \n",
    "train_ds = ds.take(train_split); train_ds.class_names = ds.class_names\n",
    "validation_ds = ds.skip(train_split); validation_ds.class_names = ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3df2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = ViTClassfier(hparams.image_size, hparams.n_classes)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\", BalancedSparseCategoricalAccuracy()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08a0f686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 [==============================] - 19s 284ms/step - loss: 0.1770 - accuracy: 0.9305 - balanced_sparse_categorical_accuracy: 0.9379 - val_loss: 0.0432 - val_accuracy: 0.9906 - val_balanced_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 19s 295ms/step - loss: 0.1480 - accuracy: 0.9447 - balanced_sparse_categorical_accuracy: 0.9524 - val_loss: 0.0575 - val_accuracy: 0.9886 - val_balanced_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 19s 292ms/step - loss: 0.1308 - accuracy: 0.9517 - balanced_sparse_categorical_accuracy: 0.9505 - val_loss: 0.0464 - val_accuracy: 0.9886 - val_balanced_sparse_categorical_accuracy: 0.9788\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 21s 322ms/step - loss: 0.1182 - accuracy: 0.9553 - balanced_sparse_categorical_accuracy: 0.9530 - val_loss: 0.0498 - val_accuracy: 0.9844 - val_balanced_sparse_categorical_accuracy: 0.9842\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 22s 330ms/step - loss: 0.1172 - accuracy: 0.9567 - balanced_sparse_categorical_accuracy: 0.9584 - val_loss: 0.0351 - val_accuracy: 0.9917 - val_balanced_sparse_categorical_accuracy: 0.9925\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 21s 324ms/step - loss: 0.0957 - accuracy: 0.9700 - balanced_sparse_categorical_accuracy: 0.9664 - val_loss: 0.0351 - val_accuracy: 0.9906 - val_balanced_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 0.0773 - accuracy: 0.9714 - balanced_sparse_categorical_accuracy: 0.9713 - val_loss: 0.0413 - val_accuracy: 0.9896 - val_balanced_sparse_categorical_accuracy: 0.9926\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0754 - accuracy: 0.9695 - balanced_sparse_categorical_accuracy: 0.9723 - val_loss: 0.0202 - val_accuracy: 0.9906 - val_balanced_sparse_categorical_accuracy: 0.9929\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0623 - accuracy: 0.9788 - balanced_sparse_categorical_accuracy: 0.9810 - val_loss: 0.0191 - val_accuracy: 0.9938 - val_balanced_sparse_categorical_accuracy: 0.9952\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 19s 284ms/step - loss: 0.0737 - accuracy: 0.9709 - balanced_sparse_categorical_accuracy: 0.9753 - val_loss: 0.0237 - val_accuracy: 0.9969 - val_balanced_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 19s 283ms/step - loss: 0.0510 - accuracy: 0.9812 - balanced_sparse_categorical_accuracy: 0.9834 - val_loss: 0.0088 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9994\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 18s 268ms/step - loss: 0.0616 - accuracy: 0.9784 - balanced_sparse_categorical_accuracy: 0.9791 - val_loss: 0.0166 - val_accuracy: 0.9948 - val_balanced_sparse_categorical_accuracy: 0.9955\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 18s 267ms/step - loss: 0.0607 - accuracy: 0.9798 - balanced_sparse_categorical_accuracy: 0.9793 - val_loss: 0.0289 - val_accuracy: 0.9938 - val_balanced_sparse_categorical_accuracy: 0.9945\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 18s 275ms/step - loss: 0.0616 - accuracy: 0.9786 - balanced_sparse_categorical_accuracy: 0.9824 - val_loss: 0.0224 - val_accuracy: 0.9969 - val_balanced_sparse_categorical_accuracy: 0.9961\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0422 - accuracy: 0.9853 - balanced_sparse_categorical_accuracy: 0.9865 - val_loss: 0.0076 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0476 - accuracy: 0.9851 - balanced_sparse_categorical_accuracy: 0.9845 - val_loss: 0.0169 - val_accuracy: 0.9969 - val_balanced_sparse_categorical_accuracy: 0.9953\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 19s 288ms/step - loss: 0.0417 - accuracy: 0.9829 - balanced_sparse_categorical_accuracy: 0.9845 - val_loss: 0.0061 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9988\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0408 - accuracy: 0.9861 - balanced_sparse_categorical_accuracy: 0.9842 - val_loss: 0.0219 - val_accuracy: 0.9917 - val_balanced_sparse_categorical_accuracy: 0.9924\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 0.0599 - accuracy: 0.9786 - balanced_sparse_categorical_accuracy: 0.9760 - val_loss: 0.0078 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 19s 282ms/step - loss: 0.0388 - accuracy: 0.9877 - balanced_sparse_categorical_accuracy: 0.9892 - val_loss: 0.0047 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9994\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0333 - accuracy: 0.9889 - balanced_sparse_categorical_accuracy: 0.9913 - val_loss: 0.0040 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0317 - accuracy: 0.9894 - balanced_sparse_categorical_accuracy: 0.9913 - val_loss: 0.0038 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9993\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0348 - accuracy: 0.9870 - balanced_sparse_categorical_accuracy: 0.9881 - val_loss: 0.0094 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 18s 282ms/step - loss: 0.0389 - accuracy: 0.9873 - balanced_sparse_categorical_accuracy: 0.9889 - val_loss: 0.0032 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 18s 275ms/step - loss: 0.0429 - accuracy: 0.9853 - balanced_sparse_categorical_accuracy: 0.9856 - val_loss: 0.0106 - val_accuracy: 0.9948 - val_balanced_sparse_categorical_accuracy: 0.9946\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0253 - accuracy: 0.9889 - balanced_sparse_categorical_accuracy: 0.9901 - val_loss: 0.0068 - val_accuracy: 0.9969 - val_balanced_sparse_categorical_accuracy: 0.9940\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0261 - accuracy: 0.9911 - balanced_sparse_categorical_accuracy: 0.9897 - val_loss: 0.0052 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9992\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 0.0393 - accuracy: 0.9868 - balanced_sparse_categorical_accuracy: 0.9875 - val_loss: 0.0076 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0278 - accuracy: 0.9909 - balanced_sparse_categorical_accuracy: 0.9859 - val_loss: 0.0014 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 20s 298ms/step - loss: 0.0234 - accuracy: 0.9913 - balanced_sparse_categorical_accuracy: 0.9933 - val_loss: 0.0033 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9993\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0317 - accuracy: 0.9894 - balanced_sparse_categorical_accuracy: 0.9846 - val_loss: 0.0031 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9954\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0368 - accuracy: 0.9882 - balanced_sparse_categorical_accuracy: 0.9892 - val_loss: 0.0030 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 0.0146 - accuracy: 0.9942 - balanced_sparse_categorical_accuracy: 0.9956 - val_loss: 0.0049 - val_accuracy: 0.9969 - val_balanced_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 19s 282ms/step - loss: 0.0370 - accuracy: 0.9868 - balanced_sparse_categorical_accuracy: 0.9839 - val_loss: 0.0046 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0266 - accuracy: 0.9909 - balanced_sparse_categorical_accuracy: 0.9876 - val_loss: 0.0020 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9994\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0502 - accuracy: 0.9839 - balanced_sparse_categorical_accuracy: 0.9785 - val_loss: 0.0054 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9993\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0272 - accuracy: 0.9906 - balanced_sparse_categorical_accuracy: 0.9907 - val_loss: 5.9537e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0243 - accuracy: 0.9911 - balanced_sparse_categorical_accuracy: 0.9918 - val_loss: 8.4568e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0319 - accuracy: 0.9894 - balanced_sparse_categorical_accuracy: 0.9915 - val_loss: 0.0062 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 18s 275ms/step - loss: 0.0295 - accuracy: 0.9904 - balanced_sparse_categorical_accuracy: 0.9913 - val_loss: 0.0037 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9991\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 0.0377 - accuracy: 0.9880 - balanced_sparse_categorical_accuracy: 0.9879 - val_loss: 0.0023 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0173 - accuracy: 0.9950 - balanced_sparse_categorical_accuracy: 0.9956 - val_loss: 0.0017 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0261 - accuracy: 0.9904 - balanced_sparse_categorical_accuracy: 0.9876 - val_loss: 0.0041 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 19s 283ms/step - loss: 0.0383 - accuracy: 0.9889 - balanced_sparse_categorical_accuracy: 0.9862 - val_loss: 0.0204 - val_accuracy: 0.9948 - val_balanced_sparse_categorical_accuracy: 0.9864\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0214 - accuracy: 0.9921 - balanced_sparse_categorical_accuracy: 0.9926 - val_loss: 0.0128 - val_accuracy: 0.9948 - val_balanced_sparse_categorical_accuracy: 0.9962\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0261 - accuracy: 0.9921 - balanced_sparse_categorical_accuracy: 0.9901 - val_loss: 0.0064 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9961\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0258 - accuracy: 0.9911 - balanced_sparse_categorical_accuracy: 0.9923 - val_loss: 0.0125 - val_accuracy: 0.9969 - val_balanced_sparse_categorical_accuracy: 0.9940\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 0.0433 - accuracy: 0.9865 - balanced_sparse_categorical_accuracy: 0.9884 - val_loss: 0.0031 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9992\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0179 - accuracy: 0.9925 - balanced_sparse_categorical_accuracy: 0.9931 - val_loss: 0.0078 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9992\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 18s 275ms/step - loss: 0.0190 - accuracy: 0.9933 - balanced_sparse_categorical_accuracy: 0.9944 - val_loss: 0.0093 - val_accuracy: 0.9969 - val_balanced_sparse_categorical_accuracy: 0.9966\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0253 - accuracy: 0.9909 - balanced_sparse_categorical_accuracy: 0.9867 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 18s 275ms/step - loss: 0.0231 - accuracy: 0.9928 - balanced_sparse_categorical_accuracy: 0.9928 - val_loss: 0.0030 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0193 - accuracy: 0.9928 - balanced_sparse_categorical_accuracy: 0.9932 - val_loss: 0.0025 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9991\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0220 - accuracy: 0.9933 - balanced_sparse_categorical_accuracy: 0.9940 - val_loss: 0.0033 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0309 - accuracy: 0.9911 - balanced_sparse_categorical_accuracy: 0.9918 - val_loss: 0.0021 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0252 - accuracy: 0.9921 - balanced_sparse_categorical_accuracy: 0.9933 - val_loss: 0.0038 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0173 - accuracy: 0.9935 - balanced_sparse_categorical_accuracy: 0.9950 - val_loss: 5.1043e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0233 - accuracy: 0.9911 - balanced_sparse_categorical_accuracy: 0.9922 - val_loss: 0.0013 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0169 - accuracy: 0.9952 - balanced_sparse_categorical_accuracy: 0.9959 - val_loss: 3.3699e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 19s 285ms/step - loss: 0.0200 - accuracy: 0.9957 - balanced_sparse_categorical_accuracy: 0.9954 - val_loss: 5.0722e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0118 - accuracy: 0.9964 - balanced_sparse_categorical_accuracy: 0.9966 - val_loss: 0.0021 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9960\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0147 - accuracy: 0.9940 - balanced_sparse_categorical_accuracy: 0.9942 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 19s 282ms/step - loss: 0.0171 - accuracy: 0.9925 - balanced_sparse_categorical_accuracy: 0.9924 - val_loss: 0.0065 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0332 - accuracy: 0.9906 - balanced_sparse_categorical_accuracy: 0.9914 - val_loss: 0.0065 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0234 - accuracy: 0.9918 - balanced_sparse_categorical_accuracy: 0.9848 - val_loss: 2.5366e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 18s 282ms/step - loss: 0.0188 - accuracy: 0.9930 - balanced_sparse_categorical_accuracy: 0.9931 - val_loss: 0.0032 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 0.0133 - accuracy: 0.9954 - balanced_sparse_categorical_accuracy: 0.9967 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0141 - accuracy: 0.9957 - balanced_sparse_categorical_accuracy: 0.9962 - val_loss: 5.0295e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "65/65 [==============================] - 18s 274ms/step - loss: 0.0124 - accuracy: 0.9952 - balanced_sparse_categorical_accuracy: 0.9960 - val_loss: 0.0019 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 18s 272ms/step - loss: 0.0216 - accuracy: 0.9923 - balanced_sparse_categorical_accuracy: 0.9917 - val_loss: 0.0013 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 18s 274ms/step - loss: 0.0170 - accuracy: 0.9930 - balanced_sparse_categorical_accuracy: 0.9840 - val_loss: 0.0022 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9962\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 18s 274ms/step - loss: 0.0298 - accuracy: 0.9925 - balanced_sparse_categorical_accuracy: 0.9861 - val_loss: 0.0212 - val_accuracy: 0.9938 - val_balanced_sparse_categorical_accuracy: 0.9940\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 18s 273ms/step - loss: 0.0361 - accuracy: 0.9892 - balanced_sparse_categorical_accuracy: 0.9909 - val_loss: 0.0024 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 18s 274ms/step - loss: 0.0220 - accuracy: 0.9928 - balanced_sparse_categorical_accuracy: 0.9906 - val_loss: 0.0048 - val_accuracy: 0.9969 - val_balanced_sparse_categorical_accuracy: 0.9955\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 18s 274ms/step - loss: 0.0182 - accuracy: 0.9942 - balanced_sparse_categorical_accuracy: 0.9925 - val_loss: 0.0179 - val_accuracy: 0.9969 - val_balanced_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 0.0186 - accuracy: 0.9942 - balanced_sparse_categorical_accuracy: 0.9929 - val_loss: 0.0046 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 19s 282ms/step - loss: 0.0360 - accuracy: 0.9892 - balanced_sparse_categorical_accuracy: 0.9909 - val_loss: 0.0027 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9984\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0275 - accuracy: 0.9904 - balanced_sparse_categorical_accuracy: 0.9874 - val_loss: 7.9782e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0268 - accuracy: 0.9916 - balanced_sparse_categorical_accuracy: 0.9827 - val_loss: 0.0020 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0174 - accuracy: 0.9957 - balanced_sparse_categorical_accuracy: 0.9963 - val_loss: 0.0020 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9994\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0205 - accuracy: 0.9928 - balanced_sparse_categorical_accuracy: 0.9944 - val_loss: 0.0027 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0101 - accuracy: 0.9962 - balanced_sparse_categorical_accuracy: 0.9969 - val_loss: 0.0046 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0124 - accuracy: 0.9954 - balanced_sparse_categorical_accuracy: 0.9941 - val_loss: 0.0043 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0217 - accuracy: 0.9928 - balanced_sparse_categorical_accuracy: 0.9932 - val_loss: 0.0057 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0203 - accuracy: 0.9937 - balanced_sparse_categorical_accuracy: 0.9940 - val_loss: 0.0018 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9992\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 0.0158 - accuracy: 0.9957 - balanced_sparse_categorical_accuracy: 0.9967 - val_loss: 0.0032 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 0.0100 - accuracy: 0.9962 - balanced_sparse_categorical_accuracy: 0.9971 - val_loss: 9.5574e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 19s 283ms/step - loss: 0.0067 - accuracy: 0.9978 - balanced_sparse_categorical_accuracy: 0.9982 - val_loss: 0.0017 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9993\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0263 - accuracy: 0.9925 - balanced_sparse_categorical_accuracy: 0.9869 - val_loss: 0.0157 - val_accuracy: 0.9948 - val_balanced_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0207 - accuracy: 0.9933 - balanced_sparse_categorical_accuracy: 0.9930 - val_loss: 0.0026 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 0.0107 - accuracy: 0.9971 - balanced_sparse_categorical_accuracy: 0.9978 - val_loss: 0.0011 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9990\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0182 - accuracy: 0.9942 - balanced_sparse_categorical_accuracy: 0.9952 - val_loss: 0.0038 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9986\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 19s 285ms/step - loss: 0.0108 - accuracy: 0.9966 - balanced_sparse_categorical_accuracy: 0.9972 - val_loss: 0.0014 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9990\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.0357 - accuracy: 0.9892 - balanced_sparse_categorical_accuracy: 0.9911 - val_loss: 0.0021 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0166 - accuracy: 0.9945 - balanced_sparse_categorical_accuracy: 0.9935 - val_loss: 0.0038 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0217 - accuracy: 0.9940 - balanced_sparse_categorical_accuracy: 0.9951 - val_loss: 0.0046 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0229 - accuracy: 0.9916 - balanced_sparse_categorical_accuracy: 0.9918 - val_loss: 0.0079 - val_accuracy: 0.9979 - val_balanced_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0161 - accuracy: 0.9952 - balanced_sparse_categorical_accuracy: 0.9949 - val_loss: 0.0022 - val_accuracy: 0.9990 - val_balanced_sparse_categorical_accuracy: 0.9953\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0123 - accuracy: 0.9964 - balanced_sparse_categorical_accuracy: 0.9966 - val_loss: 6.9245e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 0.0226 - accuracy: 0.9933 - balanced_sparse_categorical_accuracy: 0.9903 - val_loss: 6.2255e-04 - val_accuracy: 1.0000 - val_balanced_sparse_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e720077d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=100, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "251bd26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132,   0,   0,   0],\n",
       "       [  0,   8,   0,   0],\n",
       "       [  0,   0, 496,   0],\n",
       "       [  0,   0,   0, 325]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X, y_true = list(zip(*[(X, y) for (X, y) in validation_ds.unbatch().as_numpy_iterator()]))\n",
    "y_hat = model.predict_on_batch(np.array(X)).argmax(axis=-1)\n",
    "mat = confusion_matrix(y_true, y_hat)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd9b1c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on validation set : 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "acc = balanced_accuracy_score(y_true, y_hat)\n",
    "print(f\"Final accuracy on validation set : {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c478279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('path_to_my_model',save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5576ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vits.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vits.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"vits.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac233f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
